{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDD1tKST8kCr"
      },
      "source": [
        "- **Thuật toán K-Nearest Neighbors (KNN) (K láng giềng gần nhất)**\n",
        "  - **Định nghĩa đơn giản**:\n",
        "    - KNN là thuật toán dựa vào các ví dụ \"gần nhất\" trong dữ liệu đã có.\n",
        "    - Khi cần dự đoán cho một trường hợp mới, KNN sẽ tìm k trường hợp trước đó có các yếu tố tương tự và xem kết quả là gì.\n",
        "    - Dựa trên kết quả này, KNN đưa ra dự đoán cho trường hợp mới.\n",
        "  - **Ví dụ đơn giản**:\n",
        "    - Giả sử một học sinh muốn dự đoán điểm số của mình trong lần thi sắp tới.\n",
        "    - Em ấy có thể tìm điểm số của những lần thi gần nhất mà điều kiện học tập của em ấy tương tự (thời gian học, số lần ôn tập, vv).\n",
        "    - Dựa vào các điểm số trước đó, em ấy có thể ước lượng điểm thi sắp tới của mình.\n",
        "  - **Ứng dụng vào dự đoán xác suất lũ lụt**:\n",
        "    - Trong bài toán dự đoán lũ, KNN sẽ xem xét những ngày trong quá khứ có điều kiện thời tiết, cường độ mưa, và các yếu tố tương tự.\n",
        "    - Ví dụ, nếu có một ngày nào đó có lượng mưa và độ ẩm giống với những ngày trước đó đã từng xảy ra lũ, KNN sẽ dự đoán rằng ngày mới này cũng có nguy cơ cao xảy ra lũ lụt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mi_dF428kDK"
      },
      "source": [
        "# 0. CHUẨN HÓA DỮ LIỆU - Nhận xét tại notebook 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBihzo4V8kDL"
      },
      "source": [
        "### **1. Chuẩn hóa là gì?**\n",
        "Chuẩn hóa là kỹ thuật chuyển đổi các giá trị của dữ liệu về cùng một phạm vi, thường là từ **0 đến 1** hoặc biến đổi để có giá trị trung bình là **0** và độ lệch chuẩn là **1**.\n",
        "\n",
        "### **2. Giải thích chuẩn hóa một cách dễ hiểu (Ví dụ về bài toán giá nhà)**\n",
        "\n",
        "Hãy tưởng tượng chúng ta đang xây dựng một mô hình để **dự đoán giá nhà**, với các yếu tố sau:\n",
        "- **Diện tích nhà:** Tính bằng **mét vuông**, thường có giá trị từ 50 đến 500 m².\n",
        "- **Khoảng cách tới trung tâm thành phố:** Tính bằng **kilômét**, thường có giá trị từ 1 đến 50 km.\n",
        "- **Số phòng ngủ:** Là số nguyên, thường từ 1 đến 5.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tại sao cần chuẩn hóa?**\n",
        "\n",
        "#### **Thang đo không đồng nhất:**\n",
        "- Diện tích nhà có giá trị từ **50 đến 500**, quá lớn so với các yếu tố khác.\n",
        "- Khoảng cách tới trung tâm chỉ từ **1 đến 50**.\n",
        "- Số phòng ngủ từ **1 đến 5**.\n",
        "\n",
        "Khi mô hình học, nó sẽ coi **diện tích nhà** là yếu tố quan trọng nhất chỉ vì giá trị của nó **lớn hơn**, dù trong thực tế, **khoảng cách tới trung tâm** có thể ảnh hưởng lớn hơn đến giá nhà.\n",
        "\n",
        "#### **Giải pháp: Chuẩn hóa dữ liệu**\n",
        "Quy đổi tất cả các yếu tố về cùng một phạm vi (0 đến 1). Ví dụ:\n",
        "- **Diện tích nhà:** Nếu là 250 m² (giữa khoảng 50-500), sẽ trở thành **0.5**.\n",
        "- **Khoảng cách tới trung tâm:** Nếu là 25 km (giữa khoảng 1-50), sẽ trở thành **0.5**.\n",
        "- **Số phòng ngủ:** Nếu là 3 (giữa khoảng 1-5), sẽ trở thành **0.5**.\n",
        "\n",
        "Khi đó, mô hình sẽ đánh giá các yếu tố **dựa trên mối quan hệ thực sự** thay vì kích thước giá trị của chúng.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Ứng dụng chuẩn hóa vào bài toán dự đoán bão lũ**\n",
        "\n",
        "Trong bài toán dự đoán xác suất lũ lụt, chúng ta cũng có nhiều yếu tố với **thang đo khác nhau**. Ví dụ:\n",
        "- **Lượng mưa:** Có giá trị lớn, từ 0 đến vài ngàn mm.\n",
        "- **Chất lượng đê điều:** Là số điểm từ 0 đến 10.\n",
        "- **Mật độ dân số:** Có thể dao động từ vài chục đến hàng nghìn người/km².\n",
        "\n",
        "#### **Vấn đề nếu không chuẩn hóa:**\n",
        "- **Lượng mưa** có giá trị lớn sẽ được mô hình coi là yếu tố quan trọng nhất, ngay cả khi nó không phải yếu tố quyết định duy nhất.\n",
        "- Các yếu tố như chất lượng đê điều, dù quan trọng, có giá trị nhỏ hơn, sẽ bị **bỏ qua**.\n",
        "\n",
        "#### **Lợi ích khi chuẩn hóa:**\n",
        "- **Tất cả các yếu tố đều được đánh giá công bằng.**\n",
        "- Mô hình Linear Regression hoặc các biến thể như Ridge, Lasso sẽ chính xác hơn khi tính toán hệ số (coefficients) cho từng yếu tố.\n",
        "- Giảm nguy cơ mô hình \"hiểu nhầm\" về tầm quan trọng của các biến.\n",
        "\n",
        "---\n",
        "\n",
        "### **Kết luận:**\n",
        "Chuẩn hóa không chỉ giúp mô hình hoạt động chính xác hơn mà còn đảm bảo rằng các yếu tố trong bài toán **được đánh giá công bằng**. Trong bài toán dự đoán lũ lụt, việc chuẩn hóa các yếu tố như lượng mưa, chất lượng đê điều, và mật độ dân số sẽ giúp mô hình phản ánh đúng thực tế hơn và đưa ra dự đoán đáng tin cậy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sje6G8uh8kDM"
      },
      "source": [
        "# Basic KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b4MA-gO8kDN",
        "outputId": "dc1ab4cf-ba24-459a-9604-e1970173af5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPl4mmKu8kDR",
        "outputId": "8dfe7e2d-8257-43f0-aa97-7a002ab7800d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully from Local: 'train.csv'.\n",
            "Train RMSE: 1.1368572023425654e-09\n",
            "Test RMSE: 0.04054076156925334\n",
            "Train R² Score: 0.9999999999999994\n",
            "Test R² Score: 0.3037838734799907\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "# 1. Đọc dữ liệu\n",
        "try:\n",
        "    flood_data = pd.read_csv('train.csv')\n",
        "    print(\"Dataset loaded successfully from Local: 'train.csv'.\")\n",
        "except FileNotFoundError:\n",
        "    try:\n",
        "        flood_data = pd.read_csv('/content/train.csv')\n",
        "        print(\"Dataset loaded successfully from Google Colab: '/content/train.csv'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Dataset not found in either specified path.\")\n",
        "\n",
        "# Lấy 1 bộ nhỏ để thử chạy\n",
        "sampleflood_data = flood_data[:1000]\n",
        "\n",
        "X = sampleflood_data.drop('FloodProbability', axis=1)  # Tất cả các features\n",
        "y = sampleflood_data['FloodProbability']  # Biến mục tiêu\n",
        "\n",
        "# Chia tập dữ liệu\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Chuẩn hóa dữ liệu\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Khởi tạo mô hình KNN với k=3\n",
        "knn = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Dự đoán\n",
        "y_train_pred = knn.predict(X_train_scaled)\n",
        "y_test_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "# Đánh giá mô hình\n",
        "print(\"Train RMSE:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
        "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
        "print(\"Train R² Score:\", r2_score(y_train, y_train_pred))\n",
        "print(\"Test R² Score:\", r2_score(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjN6C2zVAS4R"
      },
      "source": [
        "## Chạy hết bộ lớn khá lâu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8pzZa65AVbF",
        "outputId": "9e5113de-b46e-4d26-8df2-b0f70c04d86b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully from Local: 'train.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "# 1. Đọc dữ liệu\n",
        "try:\n",
        "    flood_data = pd.read_csv('train.csv')\n",
        "    print(\"Dataset loaded successfully from Local: 'train.csv'.\")\n",
        "except FileNotFoundError:\n",
        "    try:\n",
        "        flood_data = pd.read_csv('/content/train.csv')\n",
        "        print(\"Dataset loaded successfully from Google Colab: '/content/train.csv'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Dataset not found in either specified path.\")\n",
        "\n",
        "# # Lấy 1 bộ nhỏ để thử chạy\n",
        "# sampleflood_data = flood_data\n",
        "\n",
        "X = flood_data.drop('FloodProbability', axis=1)  # Tất cả các features\n",
        "y = flood_data['FloodProbability']  # Biến mục tiêu\n",
        "\n",
        "# Chia tập dữ liệu\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Chuẩn hóa dữ liệu\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Khởi tạo mô hình KNN với k=3\n",
        "knn = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Dự đoán\n",
        "y_train_pred = knn.predict(X_train_scaled)\n",
        "y_test_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "# Đánh giá mô hình\n",
        "print(\"Train RMSE:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
        "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
        "print(\"Train R² Score:\", r2_score(y_train, y_train_pred))\n",
        "print(\"Test R² Score:\", r2_score(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if_ClIa1AthB"
      },
      "source": [
        "SAU 32 PHÚT CHẠY, TA THU ĐƯỢC KẾT QUẢ:\n",
        "```\n",
        "Train RMSE: 1.2518130869377174e-09\n",
        "Test RMSE: 0.031842760655068955\n",
        "Train R² Score: 0.9999999999999994\n",
        "Test R² Score: 0.6099863954320361\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PVsSIJAy0y"
      },
      "source": [
        "Kết quả KNN cho thấy bị overfitting khá nhiều (tức là kết quả CÓ HIỆU SUẤT CAO:0.999 trên tập TRAIN, nhưng lại CHO KẾT QUẢ KHÔNG TỐT trên tập TEST)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Đóng gói metrics: "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
