{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để cải thiện hiệu suất của Linear Regression, ngoài việc sử dụng các biến thể như Lasso, Ridge, hay Elastic Net, bạn có thể áp dụng một số kỹ thuật đặc biệt giúp tối ưu mô hình và xử lý dữ liệu tốt hơn. Dưới đây là các cách có thể áp dụng:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Feature Engineering (Kỹ thuật tạo đặc trưng)**  \n",
    "Tăng cường thông tin của dữ liệu bằng cách thêm các đặc trưng mới hoặc biến đổi đặc trưng hiện có:\n",
    "- **Tạo đặc trưng tương tác:**  \n",
    "  - Tạo các biến nhân đôi hoặc tổ hợp giữa các biến, ví dụ: `Feature_A * Feature_B`.  \n",
    "  - Mô hình sẽ học được các mối quan hệ phức tạp hơn.\n",
    "- **Sử dụng các biến phi tuyến:**  \n",
    "  - Thêm các biến dạng bình phương hoặc log, ví dụ: `Feature_A^2`, `log(Feature_B)`.  \n",
    "  - Điều này đặc biệt hữu ích khi mối quan hệ giữa biến độc lập và biến mục tiêu không tuyến tính.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Polynomial Regression (Hồi quy đa thức)**  \n",
    "Linear Regression giả định quan hệ tuyến tính giữa các biến, nhưng nếu mối quan hệ phức tạp hơn, bạn có thể mở rộng thành hồi quy đa thức:\n",
    "- **Ý tưởng:** Tạo các đặc trưng đa thức từ các biến đầu vào.\n",
    "- **Thực hiện:**\n",
    "  ```python\n",
    "  from sklearn.preprocessing import PolynomialFeatures\n",
    "  poly = PolynomialFeatures(degree=2)\n",
    "  X_poly = poly.fit_transform(X)\n",
    "  model = LinearRegression()\n",
    "  model.fit(X_poly, y)\n",
    "  ```\n",
    "- **Lưu ý:** Đừng chọn bậc quá cao (degree lớn) vì dễ dẫn đến overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Feature Scaling (Chuẩn hóa dữ liệu)**  \n",
    "Linear Regression nhạy cảm với thang đo của các biến. Sử dụng chuẩn hóa để đưa các biến về cùng một phạm vi:\n",
    "- **StandardScaler:** Biến đổi dữ liệu để có giá trị trung bình 0 và độ lệch chuẩn 1.\n",
    "- **MinMaxScaler:** Chuẩn hóa dữ liệu về khoảng [0, 1].\n",
    "- **Thực hiện:**\n",
    "  ```python\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  scaler = StandardScaler()\n",
    "  X_scaled = scaler.fit_transform(X)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Outlier Detection and Treatment (Xử lý ngoại lai)**  \n",
    "Ngoại lai (outlier) có thể ảnh hưởng lớn đến Linear Regression:\n",
    "- **Phát hiện:** Sử dụng Boxplot hoặc Z-score.\n",
    "- **Xử lý:**\n",
    "  - Loại bỏ ngoại lai (nếu không quan trọng).\n",
    "  - Chuyển đổi ngoại lai thành giá trị hợp lý hơn (thay bằng giá trị trung bình hoặc ngưỡng cận trên/dưới).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Regularization Techniques (Kỹ thuật điều chuẩn)**  \n",
    "Nếu chưa áp dụng, hãy thử:\n",
    "- **Elastic Net:** Kết hợp L1 (Lasso) và L2 (Ridge) để tận dụng ưu điểm của cả hai.\n",
    "- **Tuning Alpha (Siêu tham số):**\n",
    "  - Thử nghiệm giá trị `alpha` phù hợp bằng cách sử dụng Grid Search hoặc Random Search.\n",
    "  ```python\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.linear_model import ElasticNet\n",
    "  param_grid = {'alpha': [0.1, 1, 10], 'l1_ratio': [0.2, 0.5, 0.8]}\n",
    "  grid = GridSearchCV(ElasticNet(), param_grid, cv=5)\n",
    "  grid.fit(X_train, y_train)\n",
    "  print(grid.best_params_)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Cross-Validation (Kiểm định chéo)**  \n",
    "Thay vì chia train/test một lần, sử dụng k-fold cross-validation để đánh giá hiệu suất mô hình:\n",
    "- **Ý tưởng:** Chia dữ liệu thành k phần, mỗi phần được sử dụng làm tập test một lần.\n",
    "- **Thực hiện:**\n",
    "  ```python\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "  print(\"Cross-validated R² score:\", scores.mean())\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Robust Linear Regression**  \n",
    "Sử dụng các mô hình Linear Regression nâng cao, chịu ảnh hưởng ít hơn bởi ngoại lai:\n",
    "- **Huber Regression:** Mạnh mẽ hơn với dữ liệu có ngoại lai.\n",
    "  ```python\n",
    "  from sklearn.linear_model import HuberRegressor\n",
    "  model = HuberRegressor()\n",
    "  model.fit(X_train, y_train)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Dimensionality Reduction (Giảm số chiều)**  \n",
    "Nếu dữ liệu có quá nhiều biến dư thừa:\n",
    "- **Principal Component Analysis (PCA):**  \n",
    "  Chuyển dữ liệu về không gian mới với ít chiều hơn nhưng vẫn giữ lại thông tin quan trọng.\n",
    "  ```python\n",
    "  from sklearn.decomposition import PCA\n",
    "  pca = PCA(n_components=10)  # Chọn 10 thành phần chính\n",
    "  X_reduced = pca.fit_transform(X)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Ensemble Methods with Linear Regression**  \n",
    "Kết hợp Linear Regression với các phương pháp ensemble để cải thiện hiệu suất:\n",
    "- **Bagging:** Tăng cường độ ổn định của mô hình bằng cách huấn luyện nhiều mô hình trên các tập dữ liệu ngẫu nhiên.\n",
    "  ```python\n",
    "  from sklearn.ensemble import BaggingRegressor\n",
    "  model = BaggingRegressor(base_estimator=LinearRegression(), n_estimators=10, random_state=42)\n",
    "  model.fit(X_train, y_train)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Target Transformation**  \n",
    "Nếu biến mục tiêu (target) không phân phối chuẩn:\n",
    "- Áp dụng các biến đổi như `log(y)`, `sqrt(y)` trước khi huấn luyện mô hình.\n",
    "  ```python\n",
    "  import numpy as np\n",
    "  y_transformed = np.log(y + 1)  # Chuyển đổi log\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Lời khuyên:**\n",
    "- Nếu bạn muốn giữ Linear Regression, hãy thử **Feature Engineering**, **Scaling**, và **Regularization** trước.\n",
    "- Nếu hiệu suất vẫn không cải thiện đáng kể, cân nhắc sử dụng các mô hình phi tuyến khác như Random Forest hoặc Gradient Boosting. \n",
    "\n",
    "Bạn muốn thử nghiệm kỹ thuật nào trước?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
